<!DOCTYPE html>
<html>
  <head>
    <title>Latest developments in machine learning</title>
    <meta charset="utf-8">
    <meta name="author" content="Jeffrey Hanson" />
    <meta name="date" content="2017-07-18" />
    <script src="libs/htmlwidgets-0.9/htmlwidgets.js"></script>
    <script src="libs/viz-0.3/viz.js"></script>
    <link href="libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
    <script src="libs/grViz-binding-0.9.0/grViz.js"></script>
    <link rel="stylesheet" href="styles.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Latest developments in machine learning
## </br><a href="https://github.com/jeffreyhanson/abstracts-and-slides">github.com/jeffreyhanson/abstracts-and-slides</a>
### Jeffrey Hanson
### 18 July 2017

---




# XGBoost
* Extreme gradient boosted trees
* [python](https://www.python.org/) / [R](https://www.r-project.org/) / [Julia](https://julialang.org/)
* Fast and big data sets (eg. GPU support)
* Supports range of response variable types
* 8 [Kaggle]() competitions won using xgboost

---

# Example XGBoost usage


```r
# load data set
data(agaricus.train, package = "xgboost")
# number of species
length(agaricus.train$label)
```

```
## [1] 6513
```

```r
# number of traits
ncol(agaricus.train$data)
```

```
## [1] 126
```

```r
# proportion that are poisonous
mean(agaricus.train$label)
```

```
## [1] 0.4821127
```

---
# Example XGBoost usage

```r
# create parameters
p &lt;- list(max_depth = 2, eta = 1, silent = 1, nrounds = 2,
          nthread = 2,  objective = "binary:logistic",
          eval_metric = "auc")
# fit trees
bst &lt;- xgboost::xgboost(data = agaricus.train$data,
                        label = agaricus.train$label,
                        nrounds = 10, param = p)
```

```
## [1]	train-auc:0.958228 
## [2]	train-auc:0.981413 
## [3]	train-auc:0.997070 
## [4]	train-auc:0.998757 
## [5]	train-auc:0.999298 
## [6]	train-auc:0.999585 
## [7]	train-auc:0.999585 
## [8]	train-auc:0.999916 
## [9]	train-auc:0.999916 
## [10]	train-auc:1.000000
```

---
# Example XGBoost usage


```r
# variable importance
xgboost::xgb.importance(names(agaricus.train$data), model = bst)
```

```
##                            Feature        Gain        Cover  Frequency
##  1:                      odor=none 0.550461506 0.3350138692 0.15384615
##  2:                stalk-root=club 0.137207123 0.1199509779 0.03846154
##  3:              stalk-root=rooted 0.098627282 0.1023510750 0.03846154
##  4:              ring-type=pendant 0.045169588 0.0650510436 0.07692308
##  5:        spore-print-color=green 0.038261491 0.1248887414 0.11538462
##  6:       spore-print-color=purple 0.030585717 0.0306225959 0.03846154
##  7: stalk-surface-below-ring=scaly 0.026812969 0.0286806745 0.03846154
##  8:                      odor=foul 0.019262425 0.0530136354 0.07692308
##  9:                gill-size=broad 0.019015284 0.0458661400 0.07692308
## 10:                     odor=anise 0.011682573 0.0290161610 0.07692308
## 11:             gill-spacing=close 0.009340369 0.0256254732 0.07692308
## 12:                    odor=almond 0.007614195 0.0290552797 0.07692308
## 13:             stalk-root=missing 0.002291844 0.0003729885 0.03846154
## 14:        spore-print-color=white 0.001903777 0.0045319153 0.03846154
## 15:           population=clustered 0.001763858 0.0059594293 0.03846154
```

---
# Example XGBoost usage

```r
# plot tree
xgboost::xgb.plot.tree(feature_names = names(agaricus.train$data),
                       model = bst, trees = 1)
```

<div id="htmlwidget-7b0f92b9b577b7b690b6" style="width:432px;height:504px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-7b0f92b9b577b7b690b6">{"x":{"diagram":"digraph {\n\ngraph [layout = \"dot\",\n       rankdir = \"LR\"]\n\nnode [color = \"DimGray\",\n     style = \"filled\",\n     fontname = \"Helvetica\"]\n\nedge [color = \"DimGray\",\n     arrowsize = \"1.5\",\n     arrowhead = \"vee\",\n     fontname = \"Helvetica\"]\n\n  \"1\" [label = \"Tree 1\nstalk-root=rooted\nCover: 788.852\nGain: 832.545\", fillcolor = \"Beige\", shape = \"rectangle\"] \n  \"2\" [label = \"odor=none\nCover: 768.39\nGain: 569.725\", fillcolor = \"Beige\", shape = \"rectangle\"] \n  \"3\" [label = \"Leaf\nCover: 20.4624\nValue: -6.23624\", fillcolor = \"Khaki\", shape = \"oval\"] \n  \"4\" [label = \"Leaf\nCover: 458.937\nValue: 0.784718\", fillcolor = \"Khaki\", shape = \"oval\"] \n  \"5\" [label = \"Leaf\nCover: 309.453\nValue: -0.96853\", fillcolor = \"Khaki\", shape = \"oval\"] \n\"1\"->\"2\" [id = \"1\", label = \"< -0.000000953674\", style = \"bold\"] \n\"2\"->\"4\" [id = \"2\", label = \"< -0.000000953674\", style = \"bold\"] \n\"1\"->\"3\" [id = \"3\", id = \"3\", style = \"solid\"] \n\"2\"->\"5\" [id = \"4\", id = \"4\", style = \"solid\"] \n}","config":{"engine":null,"options":null}},"evals":[],"jsHooks":[]}</script>

---
# XGBoost Resources
* [user group](https://groups.google.com/forum/#!forum/xgboost-user/)
* [project repository](https://github.com/dmlc/xgboost)
* [documentation](http://xgboost.readthedocs.io/en/latest/)

---
# TensorFlow

* Roll your own model
* [python](https://www.python.org/) / [R](https://www.r-project.org/)
* Fast and big data sets (eg. GPU support)
* Make sure you grab the development version from GitHub

---
# Example TensorFlow usage


```r
# load package
library(tensorflow)

# create 100 phony x, y data points, y = x * 0.1 + 0.3
x_data &lt;- runif(100, min=0, max=1)
y_data &lt;- x_data * 0.1 + 0.3

# try to find values for W and b that compute y_data = W * x_data + b
# (we know that W should be 0.1 and b 0.3, but TensorFlow find it)
W &lt;- tf$Variable(tf$random_uniform(shape(1L), -1.0, 1.0))
b &lt;- tf$Variable(tf$zeros(shape(1L)))
y &lt;- W * x_data + b

# minimize the mean squared errors.
loss &lt;- tf$reduce_mean((y - y_data) ^ 2)
optimizer &lt;- tf$train$GradientDescentOptimizer(0.5)
train &lt;- optimizer$minimize(loss)
```

---
# Example TensorFlow usage


```r
# launch the graph and initialize the variables.
sess = tf$Session()
sess$run(tf$global_variables_initializer())
```

```r
# train the model
for (step in 1:201) {
  sess$run(train)
}
```

---
# Example TensorFlow usage


```r
# print correct answer
print(c("b" = 0.1, "W" = 0.3))
```

```
##   b   W 
## 0.1 0.3
```

```r
# print TensorFlow's estimate
print(c("b" = sess$run(b), "W" = sess$run(W)))
```

```
##          b          W 
## 0.30000189 0.09999659
```

---
# TensorFlow Resources
* [project repository](https://github.com/tensorflow/tensorflow)
* [documentation](https://www.tensorflow.org/)
* [RStudio documentation](https://tensorflow.rstudio.com/)
* [examples on GitHub](https://github.com/aymericdamien/TensorFlow-Examples)
    </textarea>
<script src="libs/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"slideNumberFormat": ""
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {window.dispatchEvent(new Event('resize'));});</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
  }
});
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
